import streamlit as st
from streamlit_option_menu import option_menu
import pandas as pd
import random
import yfinance as yf
from datetime import datetime, timedelta
from openai import OpenAI
from dotenv import load_dotenv
import os
import time
import re
import csv
from io import StringIO
from pathlib import Path
import unicodedata
import glob

# ==================== í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ====================
load_dotenv()

# ==================== OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ====================
try:
    openai_api_key = os.getenv("OPENAI_API_KEY")
    client = OpenAI(api_key=openai_api_key) if openai_api_key else None
except Exception:
    client = None

# ==================== Streamlit ê¸°ë³¸ ì„¤ì • ====================
st.set_page_config(
    page_title="ìŠ¬ê¸°ë¡œìš´ ë¬´ì—­ ë§ˆì¼€íŒ… ì„œë¹„ìŠ¤",
    page_icon="ğŸŒ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== êµ­ê°€ ì˜µì…˜ (ì„ íƒí˜•) ====================
COUNTRY_OPTIONS = [
    "United States", "Canada", "Mexico",
    "Brazil", "Argentina", "Chile",
    "United Kingdom", "Germany", "France", "Italy", "Spain", "Netherlands",
    "Sweden", "Norway", "Denmark", "Poland",
    "Turkey", "Russia",
    "United Arab Emirates", "Saudi Arabia", "Qatar", "Kuwait",
    "South Africa", "Egypt", "Nigeria",
    "China", "Japan", "South Korea", "Taiwan", "Hong Kong",
    "Singapore", "Malaysia", "Thailand", "Vietnam", "Indonesia", "Philippines", "India",
    "Australia", "New Zealand"
]

COUNTRY_TO_ISO2 = {
    "United States": "US", "Canada": "CA", "Mexico": "MX",
    "Brazil": "BR", "Argentina": "AR", "Chile": "CL",
    "United Kingdom": "GB", "Germany": "DE", "France": "FR", "Italy": "IT", "Spain": "ES", "Netherlands": "NL",
    "Sweden": "SE", "Norway": "NO", "Denmark": "DK", "Poland": "PL",
    "Turkey": "TR", "Russia": "RU",
    "United Arab Emirates": "AE", "Saudi Arabia": "SA", "Qatar": "QA", "Kuwait": "KW",
    "South Africa": "ZA", "Egypt": "EG", "Nigeria": "NG",
    "China": "CN", "Japan": "JP", "South Korea": "KR", "Taiwan": "TW", "Hong Kong": "HK",
    "Singapore": "SG", "Malaysia": "MY", "Thailand": "TH", "Vietnam": "VN", "Indonesia": "ID", "Philippines": "PH", "India": "IN",
    "Australia": "AU", "New Zealand": "NZ",
}

# ==================== CSV ì†ŒìŠ¤(íŒŒì¼ëª… ê¸°ì¤€) ====================
CSV_BUYER_FILES = {
    "KOTRA_í•´ì™¸ë°”ì´ì–´í˜„í™©_20240829": "ëŒ€í•œë¬´ì—­íˆ¬ìì§„í¥ê³µì‚¬_í•´ì™¸ë°”ì´ì–´ í˜„í™©_20240829.csv",
    "ì¡°ë‹¬ì²­_í•´ì™¸ì¡°ë‹¬_ì—…ì²´ë¬¼í’ˆ_20250821": "ì¡°ë‹¬ì²­_í•´ì™¸ì¡°ë‹¬_ì—…ì²´ë¬¼í’ˆ_20250821.csv",
    "ì¤‘ì§„ê³µ_êµ­ê°€ë³„í•´ì™¸ë°”ì´ì–´ìˆ˜_20250711": "ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ì§„í¥ê³µë‹¨_ì˜¨ë¼ì¸ìˆ˜ì¶œí”Œë«í¼ì— ë“±ë¡ëœ êµ­ê°€ë³„ í•´ì™¸ë°”ì´ì–´ ìˆ˜_20250711.csv",
    "ì¤‘ì§„ê³µ_í•´ì™¸ë°”ì´ì–´êµ¬ë§¤ì˜¤í¼_20241231": "ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ì§„í¥ê³µë‹¨_í•´ì™¸ë°”ì´ì–´ êµ¬ë§¤ì˜¤í¼ ì •ë³´_20241231.csv",
    "ì¤‘ì§„ê³µ_í•´ì™¸ë°”ì´ì–´ì¸ì½°ì´ì–´ë¦¬_20241230": "ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ì§„í¥ê³µë‹¨_í•´ì™¸ë°”ì´ì–´ ì¸ì½°ì´ì–´ë¦¬ ì‹ ì²­_20241230.csv",
    "ë¬´ë³´_í™”ì¥í’ˆë°”ì´ì–´_20200812": "í•œêµ­ë¬´ì—­ë³´í—˜ê³µì‚¬_í™”ì¥í’ˆ ë°”ì´ì–´ ì •ë³´_20200812.csv",
}

# ==================== ì‚°ì—… â†’ í‚¤ì›Œë“œ(ì˜ë¬¸) ë§¤í•‘ ====================
# ì œí’ˆ ì¹´í…Œê³ ë¦¬ ì…ë ¥ ì—†ì´ 'ì‚°ì—…'ë§Œìœ¼ë¡œ í…ìŠ¤íŠ¸ ë§¤ì¹­í•˜ê¸° ìœ„í•œ ë‚´ë¶€ ë£°
INDUSTRY_KEYWORDS = {
    "í™”ì¥í’ˆ/ë·°í‹°": [
        "cosmetics", "beauty", "skincare", "skin care", "makeup", "personal care",
        "lotion", "cream", "serum", "toner", "cleanser", "sunscreen", "mask", "fragrance"
    ],
    "ì „ìì œí’ˆ": [
        "electronics", "electronic", "device", "gadget", "semiconductor", "chip",
        "display", "battery", "charger", "adapter", "smart", "iot", "sensor", "led"
    ],
    "ì‹í’ˆ": [
        "food", "beverage", "snack", "drink", "coffee", "tea", "sauce",
        "noodle", "ramen", "instant", "frozen", "seafood", "meat", "fruit"
    ],
    "ì„¬ìœ /ì˜ë¥˜": [
        "apparel", "clothing", "garment", "textile", "fabric", "fashion",
        "yarn", "cotton", "polyester", "knit", "denim", "outerwear", "sportswear"
    ],
    "ìë™ì°¨ ë¶€í’ˆ": [
        "auto", "automotive", "car", "vehicle", "spare parts", "parts",
        "engine", "brake", "filter", "tire", "tyre", "transmission", "sensor"
    ],
    "ê¸°ê³„/ì„¤ë¹„": [
        "machinery", "equipment", "industrial", "manufacturing", "factory",
        "pump", "valve", "compressor", "tool", "robot", "automation", "cnc"
    ],
    "ì˜ë£Œê¸°ê¸°": [
        "medical", "healthcare", "diagnostic", "surgical", "hospital",
        "clinic", "monitor", "disposable", "sterile"
    ],
    "ê¸°íƒ€": ["import", "export", "trade", "sourcing", "procurement"]
}

# ==================== CSS (ì›í˜• ìœ ì§€) ====================
st.markdown("""
<style>
.block-container{ padding: 2rem 8rem 5rem !important; }  
:root{
  --bg:#ffffff; --card:#ffffff; --line:#e5e7eb; --text:#0f172a; --muted:#64748b;
  --green:#16a34a; --green-weak:#dcfce7; --danger:#ef4444; --warn:#f59e0b;
}
.main,[data-testid="stAppViewContainer"]{ background: var(--bg); }
[data-testid="stSidebar"]{ background: var(--bg); border-right: 1px solid var(--line); }
h1,h2,h3{ color: var(--text); text-shadow:none !important; }
h1{ font-weight:800; font-size:2.2rem; margin-bottom:0.25rem; }
h2{ font-weight:700; font-size:1.4rem; }
h3{ font-weight:650; font-size:1.1rem; }
.small-muted{ color: var(--muted); font-size:0.92rem; }
.stButton>button{
  background: var(--green); color:#fff; border:1px solid var(--green);
  border-radius:12px; padding:10px 14px; font-weight:700; box-shadow:none !important;
}
[data-testid="stMetric"]{
  background: var(--card); border-radius:14px; padding:14px 16px; box-shadow:none !important;
}
.stProgress > div > div > div > div{ background: var(--green) !important; }
.ticker-wrapper{
  background: var(--card); border-radius:14px; height:70px; overflow:hidden;
  position:relative; padding:12px;
}
@keyframes scroll{ 0%{transform:translateY(0);} 100%{transform:translateY(-50%);} }
.ticker-content{ display:flex; flex-direction:column; animation: scroll 28s linear infinite; }
.item-row{
  background: var(--card); padding:10px 12px; margin-bottom:10px; border-radius:12px;
  display:flex; align-items:center; gap:10px;
}
.time-tag{
  color: var(--muted); font-size:0.75rem; font-family:monospace; font-weight:700; white-space:nowrap;
}
.item-text{ font-size:0.92rem; font-weight:650; flex:1; color: var(--text); padding-left:10px; }
.badge{
  display:inline-flex; align-items:center; padding:2px 10px; border-radius:999px;
  font-size:0.75rem; font-weight:750; background:#f8fafc; color: var(--muted);
}
.streamlit-expanderHeader{
  background: var(--card) !important; border:1px solid var(--line) !important; border-radius:12px !important;
}
.logo-box{ background: var(--card); border-radius:16px; padding:16px; text-align:center; }
.logo-text{ font-size:18px; font-weight:900; color: var(--text); }
.logo-dot{
  display:inline-block; width:8px; height:8px; border-radius:999px; background: var(--green); margin-right:8px;
}
.page-header{
  position:sticky; top:0; background: var(--bg); z-index:100; padding:1rem 0;
  margin-bottom:1rem; border-bottom:2px solid var(--line);
}
</style>
""", unsafe_allow_html=True)

# ==================== ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ====================
if "page_mode" not in st.session_state:
    st.session_state.page_mode = "home"

if "chat_messages" not in st.session_state:
    st.session_state.chat_messages = [
        {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—­ ì „ë¬¸ AI ì±—ë´‡ì…ë‹ˆë‹¤. HS ì½”ë“œ, ê´€ì„¸, í†µê´€ ê·œì •ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!"}
    ]

if "matched_buyers" not in st.session_state:
    st.session_state.matched_buyers = []

# ==================== CSV ë¡œë” ìœ í‹¸ (í•œê¸€íŒŒì¼ëª…/ì¸ì½”ë”©/êµ¬ë¶„ì/ê²½ë¡œ ì»¤ë²„) ====================
def _nfc(s: str) -> str:
    return unicodedata.normalize("NFC", s)

def _find_local_csv_by_name(filename: str) -> str | None:
    target = _nfc(filename)
    candidates = [
        Path.cwd() / filename,
        Path.cwd() / "data" / filename,
        Path.cwd() / "datasets" / filename,
    ]
    for p in candidates:
        if p.exists():
            return str(p)
    for p in glob.glob("**/*.csv", recursive=True):
        base = _nfc(Path(p).name)
        if base == target:
            return str(Path(p))
    return None

def _read_csv_bytes_flexible(raw: bytes) -> tuple[pd.DataFrame, str, str]:
    encodings = ["utf-8-sig", "utf-8", "cp949", "euc-kr"]
    text = None
    used_enc = None

    for enc in encodings:
        try:
            text = raw.decode(enc)
            used_enc = enc
            break
        except Exception:
            continue

    if text is None:
        text = raw.decode("cp949", errors="replace")
        used_enc = "cp949(errors=replace)"

    sample = text[:5000]
    delim_candidates = [",", ";", "\t", "|"]
    try:
        dialect = csv.Sniffer().sniff(sample, delimiters=delim_candidates)
        sep = dialect.delimiter
    except Exception:
        sep = ","

    df = pd.read_csv(StringIO(text), sep=sep, engine="python", on_bad_lines="skip")

    # ì»¬ëŸ¼ì´ 1ê°œë©´ êµ¬ë¶„ì ì˜¤íƒ ê°€ëŠ¥ â†’ ì¬ì‹œë„
    if df.shape[1] == 1:
        for alt in delim_candidates:
            if alt == sep:
                continue
            df2 = pd.read_csv(StringIO(text), sep=alt, engine="python", on_bad_lines="skip")
            if df2.shape[1] > 1:
                df = df2
                sep = alt
                break

    return df, used_enc, sep

def _read_csv_flexible_from_path(path: str) -> tuple[pd.DataFrame, str, str]:
    raw = Path(path).read_bytes()
    return _read_csv_bytes_flexible(raw)

def _norm_col(s: str) -> str:
    s = str(s).strip().lower()
    s = re.sub(r"\s+", "", s)
    s = s.replace("-", "").replace("_", "")
    return s

def _infer_col(cols, keywords):
    normed = {c: _norm_col(c) for c in cols}
    for c, nc in normed.items():
        for kw in keywords:
            if kw in nc:
                return c
    return None

def _safe_get(row, col):
    if not col:
        return ""
    v = row.get(col)
    if pd.isna(v):
        return ""
    return str(v).strip()

def _parse_date_any(x: str):
    if not x:
        return None
    x = str(x).strip()
    for fmt in ["%Y-%m-%d", "%Y.%m.%d", "%Y/%m/%d", "%Y%m%d", "%Y-%m", "%Y.%m", "%Y/%m"]:
        try:
            return datetime.strptime(x, fmt)
        except Exception:
            continue
    return None

@st.cache_data(ttl=60 * 60)
def load_and_standardize_buyer_csv(resolved_paths: dict) -> tuple[pd.DataFrame, pd.DataFrame]:
    rows = []
    meta = []

    for source_name, path in resolved_paths.items():
        if not path:
            meta.append({"source": source_name, "status": "missing", "detail": "path not resolved"})
            continue

        try:
            df, enc, sep = _read_csv_flexible_from_path(path)
        except Exception as e:
            meta.append({"source": source_name, "status": "fail", "detail": str(e)})
            continue

        cols = list(df.columns)

        col_company = _infer_col(cols, ["íšŒì‚¬", "ê¸°ì—…", "ì—…ì²´", "ë°”ì´ì–´", "buyer", "company", "corporation", "ìƒí˜¸", "ê¸°ê´€ëª…", "ì¡°ì§"])
        col_country = _infer_col(cols, ["êµ­ê°€", "country", "nation", "ì†Œì¬êµ­", "ê±°ì£¼êµ­", "ì§€ì—­", "state"])
        col_city = _infer_col(cols, ["ë„ì‹œ", "city", "ì†Œì¬ì§€", "ì†Œì¬ë„ì‹œ", "ì§€ì—­"])
        col_product = _infer_col(cols, ["í’ˆëª©", "ì œí’ˆ", "item", "product", "ì˜¤í¼", "inquiry", "ê´€ì‹¬", "ìˆ˜ìš”", "êµ¬ë§¤", "êµ¬ë§¤í’ˆëª©"])
        col_hs = _infer_col(cols, ["hs", "hscode", "hsì½”ë“œ", "í’ˆëª©ì½”ë“œ", "ì„¸ë²ˆ"])
        col_name = _infer_col(cols, ["ë‹´ë‹¹ì", "contact", "name", "ì„±ëª…", "ëŒ€í‘œì", "buyername"])
        col_email = _infer_col(cols, ["ì´ë©”ì¼", "email", "e-mail", "ë©”ì¼"])
        col_phone = _infer_col(cols, ["ì „í™”", "phone", "tel", "ì—°ë½ì²˜", "mobile", "í•¸ë“œí°"])
        col_web = _infer_col(cols, ["ì›¹", "í™ˆí˜ì´ì§€", "website", "url", "domain", "ì‚¬ì´íŠ¸"])
        col_date = _infer_col(cols, ["ì¼ì", "ë‚ ì§œ", "ë“±ë¡", "ì‹ ì²­", "date", "created", "updated", "ì—°ë„", "year"])

        for _, r in df.iterrows():
            company = _safe_get(r, col_company) or "Unknown Company"
            country = _safe_get(r, col_country)
            city = _safe_get(r, col_city)
            product = _safe_get(r, col_product)
            hs = _safe_get(r, col_hs)
            contact = _safe_get(r, col_name)
            email = _safe_get(r, col_email)
            phone = _safe_get(r, col_phone)
            website = _safe_get(r, col_web)
            date_raw = _safe_get(r, col_date)
            dt = _parse_date_any(date_raw)

            rows.append({
                "company_name": company,
                "country": country,
                "city": city,
                "product_text": product,
                "hs_code": hs,
                "contact_person": contact,
                "email": email,
                "phone": phone,
                "website": website,
                "date": dt,
                "date_raw": date_raw,
                "source": source_name,
            })

        meta.append({
            "source": source_name,
            "status": "ok",
            "rows": len(df),
            "cols": len(cols),
            "encoding": enc,
            "sep": sep,
            "path": path,
        })

    df_all = pd.DataFrame(rows)
    df_meta = pd.DataFrame(meta)

    if not df_all.empty:
        for c in ["company_name", "country", "city", "product_text", "hs_code", "contact_person",
                  "email", "phone", "website", "date_raw", "source"]:
            df_all[c] = df_all[c].fillna("").astype(str).str.strip()

    return df_all, df_meta

def score_buyer_record(row: dict,
                       industry: str,
                       hs_code: str,
                       countries_selected: list[str],
                       require_email: bool,
                       source_weight: dict):
    """
    âœ… íŒë³„ ê¸°ì¤€: ì‚°ì—…(í‚¤ì›Œë“œ) + HS ì½”ë“œ
    - industry: product_text/company_nameì— í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê°€ì 
    - hs_code: rowì˜ hs_codeì— í¬í•¨ë˜ë©´ ê°€ì 
    - êµ­ê°€/ì—°ë½ì²˜/ì›¹/í° ë“± ê°€ì  ìœ ì§€
    """
    score = 0
    prod = (row.get("product_text", "") or "").lower()
    comp = (row.get("company_name", "") or "").lower()
    hs = (row.get("hs_code", "") or "").replace(" ", "")
    country_val = (row.get("country", "") or "").lower()

    # ì‚°ì—… í‚¤ì›Œë“œ ë§¤ì¹­
    kws = INDUSTRY_KEYWORDS.get(industry, []) or []
    if kws:
        if any(kw.lower() in prod for kw in kws):
            score += 30
        if any(kw.lower() in comp for kw in kws):
            score += 10

    # HS ë§¤ì¹­
    if hs_code:
        hk = hs_code.replace(" ", "")
        if hk and hk in hs:
            score += 45

    # êµ­ê°€ í•„í„°
    if countries_selected:
        hit = any((c.lower() in country_val) for c in countries_selected if c)
        if hit:
            score += 20
        else:
            score -= 15

    # ì—°ë½ì²˜ ê°€ì 
    if row.get("email"):
        score += 20
    if row.get("contact_person"):
        score += 8
    if row.get("phone"):
        score += 6
    if row.get("website"):
        score += 6

    # ì´ë©”ì¼ í•„ìˆ˜ ì˜µì…˜
    if require_email and not row.get("email"):
        score -= 999

    # ë‚´ë¶€ ìµœì‹ ì„± ê°€ì (í‘œì‹œì—ëŠ” ì•ˆ ì”€)
    dt = row.get("date")
    if isinstance(dt, datetime):
        days_ago = (datetime.now() - dt).days
        if days_ago <= 90:
            score += 10
        elif days_ago <= 365:
            score += 5

    # ë‚´ë¶€ ì†ŒìŠ¤ ê°€ì¤‘ì¹˜(í‘œì‹œì—ëŠ” ì•ˆ ì”€)
    score += int(source_weight.get(row.get("source", ""), 0))
    return max(-999, min(100, score))

def dedupe_buyer_candidates(records: list[dict]) -> list[dict]:
    if not records:
        return records
    df = pd.DataFrame(records)
    if df.empty:
        return records

    df["email_key"] = df["email"].fillna("").astype(str).str.lower().str.strip()
    df["cc_key"] = (
        df["company_name"].fillna("").astype(str).str.lower().str.strip()
        + "|" +
        df["country_targets"].apply(lambda x: ",".join(x) if isinstance(x, list) else str(x)).str.lower().str.strip()
    )

    with_email = df[df["email_key"] != ""].sort_values("match_score", ascending=False).drop_duplicates("email_key")
    no_email = df[df["email_key"] == ""].sort_values("match_score", ascending=False).drop_duplicates("cc_key")
    out = pd.concat([with_email, no_email], axis=0).sort_values("match_score", ascending=False)
    return out.drop(columns=["email_key", "cc_key"]).to_dict(orient="records")

# ==================== OpenAI API (ì›í˜• ìœ ì§€) ====================
def get_openai_response(prompt, system_message="ë‹¹ì‹ ì€ ë¬´ì—­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."):
    if not client:
        return "âš ï¸ OpenAI APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=900
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âš ï¸ API ì˜¤ë¥˜: {str(e)}"

def generate_buyer_email(buyer_name, country, industry, purchase_history, contact_person=None, email=None):
    prompt = f"""
ë‹¤ìŒ ë°”ì´ì–´ì—ê²Œ ë³´ë‚¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì´ë©”ì¼ì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

- íšŒì‚¬ëª…: {buyer_name}
- êµ­ê°€: {country}
- ì‚°ì—…: {industry}
- ê´€ì‹¬ ì œí’ˆ/ë²”ì£¼: {', '.join(purchase_history)}
- ë‹´ë‹¹ì(ì•Œë ¤ì§„ ê²½ìš°): {contact_person or 'ë¯¸í™•ì¸'}
- ì´ë©”ì¼(ì•Œë ¤ì§„ ê²½ìš°): {email or 'ë¯¸í™•ì¸'}

í•œêµ­ ì œí’ˆ ìˆ˜ì¶œ ì—…ì²´ë¡œì„œ íŒŒíŠ¸ë„ˆì‹­ì„ ì œì•ˆí•˜ëŠ” ì „ë¬¸ì ì´ê³  ê°„ê²°í•œ ì´ë©”ì¼ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
ì œëª©ê³¼ ë³¸ë¬¸ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
"""
    return get_openai_response(prompt, "ë‹¹ì‹ ì€ êµ­ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.")

def translate_email(email_content, target_language):
    prompt = f"""
ë‹¤ìŒ ì´ë©”ì¼ì„ {target_language}ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”.
ë¹„ì¦ˆë‹ˆìŠ¤ ì´ë©”ì¼ í†¤ì„ ìœ ì§€í•˜ì„¸ìš”.

{email_content}
"""
    return get_openai_response(prompt, "ë‹¹ì‹ ì€ ì „ë¬¸ ë¹„ì¦ˆë‹ˆìŠ¤ ë²ˆì—­ê°€ì…ë‹ˆë‹¤.")

# ==================== HOME ë°ì´í„°(ì›í˜• ìœ ì§€) ====================
def generate_news_data():
    news = [
        {"ì‹œê°„": "09:15", "ë‚´ìš©": "ğŸ‡ºğŸ‡¸ ë¯¸ ì„œì•ˆ í•­ë§Œ ì ì²´ í•´ì†Œ ê°€ì†í™”", "ì¤‘ìš”ë„": "ë†’ìŒ"},
        {"ì‹œê°„": "10:30", "ë‚´ìš©": "ğŸ‡¨ğŸ‡³ í•œ-ì•„ì„¸ì•ˆ FTA í™œìš©ë¥  ì—­ëŒ€ ìµœê³ ì¹˜ ê²½ì‹ ", "ì¤‘ìš”ë„": "ë³´í†µ"},
        {"ì‹œê°„": "11:45", "ë‚´ìš©": "ğŸ‡ªğŸ‡º EU íƒ„ì†Œêµ­ê²½ì¡°ì •ì œë„ ë³¸ê²© ì‹œí–‰ ì„ë°•", "ì¤‘ìš”ë„": "ë³´í†µ"},
        {"ì‹œê°„": "13:20", "ë‚´ìš©": "ğŸ‡°ğŸ‡· K-ë·°í‹°, ì¤‘ë™ ì‹œì¥ ì ìœ ìœ¨ 15% ëŒíŒŒ", "ì¤‘ìš”ë„": "ë†’ìŒ"},
        {"ì‹œê°„": "14:50", "ë‚´ìš©": "ğŸ‡¯ğŸ‡µ 2026 í™ì½© ê¸€ë¡œë²Œ ì†Œì‹± í˜ì–´ ê°œë§‰", "ì¤‘ìš”ë„": "ë‚®ìŒ"},
        {"ì‹œê°„": "15:30", "ë‚´ìš©": "ğŸ‡»ğŸ‡³ ë² íŠ¸ë‚¨ ì„¬ìœ  ì‚°ì—… ìˆ˜ì¶œ 30% ì¦ê°€", "ì¤‘ìš”ë„": "ë³´í†µ"},
        {"ì‹œê°„": "16:10", "ë‚´ìš©": "ğŸ‡®ğŸ‡³ ì¸ë„ IT ì„œë¹„ìŠ¤ ìˆ˜ì¶œ ê¸‰ì¦ì„¸", "ì¤‘ìš”ë„": "ë†’ìŒ"},
    ]
    return news * 4

def generate_exchange_data():
    currencies = ["USD", "EUR", "JPY", "CNY", "GBP"]
    base_rate = {"USD": 1320, "EUR": 1450, "JPY": 900, "CNY": 182, "GBP": 1680}
    out = []
    for currency in currencies:
        change = random.uniform(-3, 3)
        out.append({
            "í†µí™”": currency,
            "í˜„ì¬ê°€": f"{base_rate[currency] + change:.2f}",
            "ë³€ë™": f"{change:+.2f}",
            "ë³€ë™ë¥ ": f"{(change / base_rate[currency] * 100):+.2f}%"
        })
    return out * 4

def generate_search_trend():
    keywords = ["LED ì¡°ëª…", "í™”ì¥í’ˆ", "ìë™ì°¨ ë¶€í’ˆ", "ë°˜ë„ì²´", "ì˜ë¥˜"]
    counts = [random.randint(500, 2000) for _ in range(5)]
    return pd.DataFrame({"í‚¤ì›Œë“œ": keywords, "ê²€ìƒ‰ëŸ‰": counts})

@st.cache_data(ttl=60 * 60)
def generate_exchange_chart_data(days: int = 120):
    end = datetime.now()
    start = end - timedelta(days=days)
    symbols = {"USD/KRW": "KRW=X", "EUR/KRW": "EURKRW=X"}
    series_list = []
    for name, symbol in symbols.items():
        try:
            ticker = yf.Ticker(symbol)
            df = ticker.history(start=start, end=end)
            if not df.empty and "Close" in df.columns:
                series_list.append(df["Close"].rename(name))
        except Exception:
            continue

    if not series_list:
        dates = pd.date_range(start=start, end=end, freq="D")
        data = {
            "USD/KRW": [1320 + random.uniform(-10, 10) for _ in range(len(dates))],
            "EUR/KRW": [1450 + random.uniform(-15, 15) for _ in range(len(dates))],
        }
        return pd.DataFrame(data, index=dates).reset_index().rename(columns={"index": "Timestamp"})

    result_df = pd.concat(series_list, axis=1).reset_index()
    if "Date" in result_df.columns:
        result_df = result_df.rename(columns={"Date": "Timestamp"})
    elif "index" in result_df.columns:
        result_df = result_df.rename(columns={"index": "Timestamp"})
    result_df["Timestamp"] = pd.to_datetime(result_df["Timestamp"])
    return result_df.sort_values("Timestamp")

# ==================== ì‚¬ì´ë“œë°” ====================
with st.sidebar:
    st.markdown("""
        <div class="logo-box">
            <div class="logo-text"><span class="logo-dot"></span>ìŠ¬ê¸°ë¡œìš´ ì„œë¹„ìŠ¤</div>
            <div class="small-muted" style="margin-top:6px;">Trade Marketing Suite</div>
        </div>
    """, unsafe_allow_html=True)

    st.markdown("<br>", unsafe_allow_html=True)

    st.markdown("### ğŸ”§ ë¹ ë¥¸ ë„êµ¬")
    b1, b2 = st.columns(2)
    with b1:
        st.button("í™˜ìœ¨ ê³„ì‚°", use_container_width=True, key="calc_btn")
    with b2:
        if st.button("AI ì±—ë´‡", use_container_width=True, key="chat_btn"):
            st.session_state.page_mode = "chatbot"
            st.rerun()

    st.markdown("<br>", unsafe_allow_html=True)
    st.markdown("### ğŸ“‚ ì£¼ìš” ì„œë¹„ìŠ¤")

    nav_items = [
        {"icon": "ğŸŒ", "title": "êµ­ê°€ë³„ ìˆ˜ì¶œì… ë°ì´í„°"},
        {"icon": "ğŸ“„", "title": "ì„œë¥˜ ìë™ ì™„ì„±"},
        {"icon": "ğŸ’±", "title": "ì‹¤ì‹œê°„ í™˜ìœ¨"},
        {"icon": "ğŸ¯", "title": "SEO ì„œë¹„ìŠ¤"},
        {"icon": "ğŸ¤", "title": "AI ë°”ì´ì–´ ë§¤ì¹­ ì—”ì§„"},
    ]

    for item in nav_items:
        with st.expander(f"{item['icon']} {item['title']}"):
            st.markdown(f"**{item['title']} ì„œë¹„ìŠ¤**")
            if item["title"] == "AI ë°”ì´ì–´ ë§¤ì¹­ ì—”ì§„":
                if st.button("ë°”ë¡œê°€ê¸° â†’", key=f"nav_{item['title']}", use_container_width=True):
                    st.session_state.page_mode = "buyer_matching"
                    st.rerun()
            else:
                st.button("ë°”ë¡œê°€ê¸° â†’", key=f"nav_{item['title']}", use_container_width=True, disabled=True)

# ==================== ë¼ìš°íŒ… ====================
# HOME
if st.session_state.page_mode == "home":
    st.title("ìŠ¬ê¸°ë¡œìš´ ë¬´ì—­ ë§ˆì¼€íŒ… ì„œë¹„ìŠ¤")
    st.markdown('<div class="small-muted">ğŸš€ ìš°ë¦¬ íšŒì‚¬ì˜ ë§ˆì¼€íŒ… ì •ë³´ë¥¼ ì›ìŠ¤í†±ìœ¼ë¡œ ê²½í—˜í•´ë³´ì„¸ìš”</div>', unsafe_allow_html=True)
    st.markdown("<br>", unsafe_allow_html=True)

    option_menu(
        menu_title=None,
        options=["Home", "Task", "Theme", "Settings"],
        icons=["house-fill", "list-task", "palette-fill", "gear-fill"],
        default_index=0,
        orientation="horizontal",
        styles={
            "container": {"padding": "0!important", "background": "#ffffff", "border-radius": "16px"},
            "icon": {"color": "#16a34a", "font-size": "20px"},
            "nav-link": {
                "font-size": "15px", "text-align": "center", "margin": "6px",
                "padding": "10px 16px", "border-radius": "12px",
                "color": "#0f172a", "font-weight": "650",
                "background": "#ffffff", "border": "1px solid #e5e7eb",
            },
            "nav-link-selected": {
                "background": "#dcfce7", "color": "#166534", "font-weight": "850",
                "border": "1px solid #16a34a",
            },
        }
    )

    st.markdown("<br>", unsafe_allow_html=True)
    col1, col2 = st.columns(2)

    with col1:
        news_list = generate_news_data()
        news_html = ""
        for item in news_list:
            tone = {"ë†’ìŒ": "danger", "ë³´í†µ": "warn", "ë‚®ìŒ": "ok"}[item["ì¤‘ìš”ë„"]]
            border_color = {"danger": "var(--danger)", "warn": "var(--warn)", "ok": "var(--green)"}[tone]
            news_html += f'<div class="item-row"><span class="time-tag">[{item["ì‹œê°„"]}]</span><span class="item-text" style="border-left: 3px solid {border_color};">{item["ë‚´ìš©"]}</span><span class="badge" style="border-color:{border_color}; color:{border_color};">{item["ì¤‘ìš”ë„"]}</span></div>'
        st.markdown(f'<div class="ticker-wrapper"><div class="ticker-content">{news_html}</div></div>', unsafe_allow_html=True)

    with col2:
        exchange_list = generate_exchange_data()
        exchange_html = ""
        for item in exchange_list:
            is_positive = float(item["ë³€ë™"]) >= 0
            color = "var(--green)" if is_positive else "var(--danger)"
            arrow = "â–²" if is_positive else "â–¼"
            exchange_html += f'<div class="item-row"><div style="flex:1;"><div class="exchange-head" style="border-left: 3px solid {color};"><span class="currency-name">{item["í†µí™”"]}/KRW</span><span class="change-rate" style="color:{color};">{arrow} {item["ë³€ë™ë¥ "]}</span></div><div class="exchange-value"><span class="rate-value">{item["í˜„ì¬ê°€"]}</span><span class="change-value" style="color:{color};">({item["ë³€ë™"]})</span></div></div></div>'
        st.markdown(f'<div class="ticker-wrapper"><div class="ticker-content">{exchange_html}</div></div>', unsafe_allow_html=True)

    st.markdown("<br>", unsafe_allow_html=True)
    c1, c2, c3, c4 = st.columns(4)

    with c1:
        st.markdown("#### ğŸ“ ìˆ˜ì¶œ ì„œë¥˜ ì¤€ë¹„")
        st.progress(0.75)
        st.metric("ì§„í–‰ë¥ ", "75%", delta="â†‘ 15%")

    with c2:
        st.markdown("#### ğŸš¢ ë¬¼ë¥˜ ì²˜ë¦¬")
        st.progress(0.45)
        st.metric("ì§„í–‰ë¥ ", "45%", delta="â†“ 5%")

    with c3:
        st.markdown("#### ğŸ’¼ ë°”ì´ì–´ ë§¤ì¹­")
        st.progress(0.90)
        st.metric("ì§„í–‰ë¥ ", "90%", delta="â†‘ 20%")

    with c4:
        search_df = generate_search_trend().sort_values("ê²€ìƒ‰ëŸ‰", ascending=False).reset_index(drop=True)
        st.dataframe(search_df, use_container_width=True, hide_index=True)

    left, right = st.columns([1, 2])
    chart_data = generate_exchange_chart_data()

    with left:
        if not chart_data.empty and len(chart_data) > 1:
            latest = chart_data.iloc[-1]
            prev = chart_data.iloc[-2]
            for col_name in ["USD/KRW", "EUR/KRW"]:
                if col_name in chart_data.columns:
                    cur = float(latest[col_name])
                    prv = float(prev[col_name])
                    diff = cur - prv
                    pct = (diff / prv * 100) if prv != 0 else 0
                    st.metric(col_name, f"{cur:,.2f} ì›", f"{diff:+.2f} ({pct:+.2f}%)")

    with right:
        if not chart_data.empty and "Timestamp" in chart_data.columns:
            st.line_chart(chart_data.set_index("Timestamp"))

# CHATBOT
elif st.session_state.page_mode == "chatbot":
    st.markdown('<div class="page-header">', unsafe_allow_html=True)
    col_back, col_title = st.columns([1, 9])
    with col_back:
        if st.button("â¬…ï¸ í™ˆìœ¼ë¡œ", key="back_home_chat", use_container_width=True):
            st.session_state.page_mode = "home"
            st.rerun()
    with col_title:
        st.markdown("## ğŸ’¬ AI ë¬´ì—­ ì±—ë´‡")
    st.markdown("</div>", unsafe_allow_html=True)

    st.markdown("HS ì½”ë“œ, ê´€ì„¸, í†µê´€ ê·œì •ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!")
    st.markdown("---")

    chat_container = st.container(height=500)
    with chat_container:
        for msg in st.session_state.chat_messages:
            with st.chat_message(msg["role"]):
                st.write(msg["content"])

    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        st.session_state.chat_messages.append({"role": "user", "content": prompt})
        with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            response = get_openai_response(
                prompt,
                "ë‹¹ì‹ ì€ êµ­ì œ ë¬´ì—­ê³¼ ê´€ì„¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. HS ì½”ë“œ, í†µê´€ ê·œì •, í•„ìš” ì„œë¥˜, ê´€ì„¸ìœ¨ì— ëŒ€í•´ ì •í™•í•˜ê³  ìƒì„¸í•œ ë‹µë³€ì„ í•œêµ­ì–´ë¡œ ì œê³µí•©ë‹ˆë‹¤."
            )
            st.session_state.chat_messages.append({"role": "assistant", "content": response})
        st.rerun()

    st.markdown("<br>", unsafe_allow_html=True)
    col_btn1, _ = st.columns([1, 5])
    with col_btn1:
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”", key="reset_chat", use_container_width=True):
            st.session_state.chat_messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—­ ì „ë¬¸ AI ì±—ë´‡ì…ë‹ˆë‹¤. HS ì½”ë“œ, ê´€ì„¸, í†µê´€ ê·œì •ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!"}]
            st.rerun()

# BUYER MATCHING (CSV ê¸°ë°˜) â€” âœ… ì‚°ì—…+HSë§Œ ì‚¬ìš©
elif st.session_state.page_mode == "buyer_matching":
    st.markdown('<div class="page-header">', unsafe_allow_html=True)
    col_back, col_title = st.columns([1, 9])
    with col_back:
        if st.button("â¬…ï¸ í™ˆìœ¼ë¡œ", key="back_home_buyer", use_container_width=True):
            st.session_state.page_mode = "home"
            st.session_state.matched_buyers = []
            keys_to_delete = [k for k in st.session_state.keys()
                              if str(k).startswith("email_content_")
                              or str(k).startswith("trans_")
                              or str(k).startswith("generate_email_")]
            for k in keys_to_delete:
                del st.session_state[k]
            st.rerun()
    with col_title:
        st.markdown("## ğŸ¤ AI ë°”ì´ì–´ ë§¤ì¹­ ì—”ì§„")
    st.markdown("</div>", unsafe_allow_html=True)

    st.success("âœ… ë¡œë”© ì™„ë£Œ.")
    st.markdown("---")

    # (1) ë¡œì»¬ íŒŒì¼ ê²½ë¡œ resolve
    resolved_paths = {k: _find_local_csv_by_name(v) for k, v in CSV_BUYER_FILES.items()}

    # (2) ë°ì´í„° ë¡œë“œ/ì •ê·œí™” (UI ì—†ì´)
    with st.spinner("ğŸ“¦ CSV ë¡œë”©/ì •ê·œí™” ì¤‘..."):
        df_all, df_meta = load_and_standardize_buyer_csv(resolved_paths)

    # (3) ì…ë ¥ UI: ì œí’ˆ ì¹´í…Œê³ ë¦¬ ì—†ìŒ (ì‚°ì—… + HSë§Œ)
    left, right = st.columns(2, gap="large")

    with left:
        st.markdown("### âœï¸ ì œí’ˆ ì •ë³´ ì…ë ¥")
        industry = st.selectbox("ì‚°ì—… ë¶„ì•¼", [
            "í™”ì¥í’ˆ/ë·°í‹°", "ì „ìì œí’ˆ", "ì‹í’ˆ", "ì„¬ìœ /ì˜ë¥˜",
            "ìë™ì°¨ ë¶€í’ˆ", "ê¸°ê³„/ì„¤ë¹„", "ì˜ë£Œê¸°ê¸°", "ê¸°íƒ€"
        ])
        hs_code = st.text_input("HS ì½”ë“œ (ì„ íƒ)", placeholder="ì˜ˆ: 3304, 8517")
        max_results = st.slider("ìµœëŒ€ í›„ë³´ ìˆ˜", 10, 300, 60, 10)

    with right:
        st.markdown("### ğŸŒ íƒ€ê²Ÿ êµ­ê°€ ì„ íƒ")
        select_all = st.checkbox("âœ… ì „ì²´ ì„ íƒ", value=False, key="country_select_all_csv")
        default_countries = COUNTRY_OPTIONS if select_all else ["United States"]
        selected_countries = st.multiselect(
            "íƒ€ê²Ÿ êµ­ê°€ (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)",
            options=COUNTRY_OPTIONS,
            default=default_countries,
            key="country_multiselect_csv"
        )
        require_email = st.checkbox("ğŸ“§ ì´ë©”ì¼ ìˆëŠ” í›„ë³´ë§Œ", value=False)

    st.markdown("<br>", unsafe_allow_html=True)

    # (4) ê²€ìƒ‰ ë²„íŠ¼
    source_weight = {
        "ì¤‘ì§„ê³µ_í•´ì™¸ë°”ì´ì–´êµ¬ë§¤ì˜¤í¼_20241231": 6,
        "ì¤‘ì§„ê³µ_í•´ì™¸ë°”ì´ì–´ì¸ì½°ì´ì–´ë¦¬_20241230": 6,
        "KOTRA_í•´ì™¸ë°”ì´ì–´í˜„í™©_20240829": 4,
        "ì¡°ë‹¬ì²­_í•´ì™¸ì¡°ë‹¬_ì—…ì²´ë¬¼í’ˆ_20250821": 3,
        "ë¬´ë³´_í™”ì¥í’ˆë°”ì´ì–´_20200812": 2,
        "ì¤‘ì§„ê³µ_êµ­ê°€ë³„í•´ì™¸ë°”ì´ì–´ìˆ˜_20250711": 0,
    }

    if st.button("ğŸ” (ë°”ì´ì–´ í›„ë³´ ë°œêµ´", use_container_width=True, type="primary"):
        if df_all.empty:
            st.error("âš ï¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë°°í¬ í™˜ê²½ì—ì„œëŠ” ë¡œì»¬ì— íŒŒì¼ì´ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ í´ë”(ë˜ëŠ” data/)ì— í¬í•¨ì‹œì¼œ ì£¼ì„¸ìš”.")
        else:
            countries_selected = selected_countries[:]

            df = df_all.copy()
            df["match_score"] = df.apply(
                lambda r: score_buyer_record(
                    r.to_dict(),
                    industry=industry,
                    hs_code=hs_code.strip(),
                    countries_selected=countries_selected,
                    require_email=require_email,
                    source_weight=source_weight,
                ),
                axis=1
            )

            # HSê°€ ìˆìœ¼ë©´ ë” ì—„ê²©, ì—†ìœ¼ë©´ ì™„í™”
            if hs_code.strip():
                df = df[df["match_score"] >= 35]
            else:
                df = df[df["match_score"] >= 20]

            df = df.sort_values("match_score", ascending=False)

            buyers = []
            for _, row in df.iterrows():
                website = row.get("website", "")
                email = row.get("email", "")
                domain_guess = ""

                if website:
                    d = str(website).strip().lower()
                    d = d.replace("https://", "").replace("http://", "").split("/")[0]
                    domain_guess = d
                elif email and "@" in str(email):
                    domain_guess = str(email).split("@")[-1].strip().lower()

                buyers.append({
                    "company_name": row.get("company_name", "Unknown Company"),
                    "domain": domain_guess,
                    "website": website if website else (f"https://{domain_guess}" if domain_guess else ""),
                    "industry": industry,
                    "country_targets": selected_countries,
                    "email": email if email else (f"info@{domain_guess}" if domain_guess else ""),
                    "contact_person": row.get("contact_person", "") or "ë¯¸ì¶”ì¶œ",

                    # ë‚´ë¶€ ì •ë ¬ìš©(ì¶œë ¥ì—ì„œëŠ” ìˆ¨ê¹€)
                    "match_score": int(row.get("match_score", 0)),
                    "source": row.get("source", "CSV"),

                    # ì›ì²œ ì •ë³´ í‘œì‹œ(ìš”ì²­í•œ ê²ƒë§Œ ìœ ì§€)
                    "_raw_country": row.get("country", ""),
                    "_raw_city": row.get("city", ""),
                    "_raw_product_text": row.get("product_text", ""),
                    "_raw_hs": row.get("hs_code", ""),
                    "_raw_phone": row.get("phone", ""),
                })

            buyers = dedupe_buyer_candidates(buyers)
            buyers = buyers[:max_results]
            st.session_state.matched_buyers = buyers

            if buyers:
                st.success(f"ğŸ‰ {len(buyers)}ê°œì˜ ë°”ì´ì–´ í›„ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤! (ì‚°ì—…+HS ê¸°ë°˜)")
            else:
                st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. HS ì½”ë“œë¥¼ ì…ë ¥í•˜ê±°ë‚˜, ì‚°ì—… ë¶„ì•¼ë¥¼ ë°”ê¿”ë³´ì„¸ìš”.")

    # (5) ê²°ê³¼ í‘œì‹œ: ë‚ ì§œ/ë§¤ì¹­ì ìˆ˜/ì†ŒìŠ¤ ì¶œë ¥ì€ ì‚­ì œ ìœ ì§€
    if st.session_state.matched_buyers:
        st.markdown("---")
        st.markdown("### ğŸ¯ ê²€ìƒ‰ëœ ë°”ì´ì–´ í›„ë³´ ëª©ë¡")
        st.caption("âœ… ì´ë©”ì¼/ë‹´ë‹¹ìê°€ ì¡´ì¬í•  ê²½ìš° í‘œì‹œë©ë‹ˆë‹¤.")

        for idx, buyer in enumerate(st.session_state.matched_buyers):
            key = f"{buyer.get('domain','') or buyer.get('company_name','') }|{idx}"
            has_real_email = bool(buyer.get("email")) and ("@" in buyer.get("email", ""))
            badge = "âœ… ì—°ë½ì²˜ í™•ë³´" if has_real_email or buyer.get("contact_person") not in ["", "ë¯¸ì¶”ì¶œ"] else "ğŸ” ë¯¸í™•ì¸"

            with st.expander(
                f"**{idx+1}. {buyer['company_name']}** ({buyer.get('domain','') or 'no-domain'}) - {badge}",
                expanded=(idx == 0)
            ):
                col_info, col_action = st.columns([2, 1])

                with col_info:
                    st.markdown(f"""
**ğŸŒ ì›¹ì‚¬ì´íŠ¸:** {buyer.get('website','N/A') or 'N/A'}  
**ğŸ­ ì‚°ì—…:** {buyer.get('industry','N/A')}  
**ğŸŒ íƒ€ê²Ÿ êµ­ê°€:** {", ".join(buyer.get("country_targets", []))}  
**ğŸŒ (ì›ì²œêµ­ê°€/ë„ì‹œ):** {buyer.get("_raw_country","")} {buyer.get("_raw_city","")}  
**ğŸ“¦ (ì›ì²œ í’ˆëª©/ì˜¤í¼):** {buyer.get("_raw_product_text","") or 'N/A'}  
**ğŸ§¾ (ì›ì²œ HS):** {buyer.get("_raw_hs","") or 'N/A'}  
**ğŸ‘¤ ë‹´ë‹¹ì:** {buyer.get("contact_person","N/A")}  
**ğŸ“§ ì´ë©”ì¼:** {buyer.get("email","N/A")}  
**â˜ï¸ ì „í™”:** {buyer.get("_raw_phone","") or 'N/A'}  
""")

                with col_action:
                    st.markdown("<br>", unsafe_allow_html=True)
                    st.info("CSV ê¸°ë°˜\nì—°ë½ì²˜ê°€ ìˆìœ¼ë©´\në°”ë¡œ í‘œì‹œë©ë‹ˆë‹¤.")
                    st.markdown("<br>", unsafe_allow_html=True)

                    if st.button("âœ‰ï¸ ì œì•ˆ ì´ë©”ì¼", key=f"email_btn_{key}", use_container_width=True):
                        st.session_state[f"generate_email_{key}"] = True
                        st.rerun()

                if st.session_state.get(f"generate_email_{key}", False):
                    st.markdown("---")
                    st.markdown("#### ğŸ“§ AI ìƒì„± ì œì•ˆ ì´ë©”ì¼")

                    contact_person = buyer.get("contact_person")
                    email_addr = buyer.get("email")

                    # ê´€ì‹¬ ì œí’ˆ/ë²”ì£¼: ì‚°ì—… + HS
                    interest = [buyer.get("industry", "")]
                    if hs_code.strip():
                        interest.append(f"HS {hs_code.strip()}")

                    if f"email_content_{key}" not in st.session_state:
                        with st.spinner("AIê°€ ë§ì¶¤ ì´ë©”ì¼ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                            email_content = generate_buyer_email(
                                buyer_name=buyer.get("company_name", ""),
                                country=", ".join(buyer.get("country_targets", [])) or buyer.get("_raw_country", ""),
                                industry=buyer.get("industry", ""),
                                purchase_history=[x for x in interest if x],
                                contact_person=None if contact_person == "ë¯¸ì¶”ì¶œ" else contact_person,
                                email=email_addr
                            )
                            st.session_state[f"email_content_{key}"] = email_content

                    st.text_area("ğŸ‡°ğŸ‡· í•œêµ­ì–´ ì´ë©”ì¼", st.session_state[f"email_content_{key}"], height=280, key=f"email_kr_{key}")

                    st.markdown("#### ğŸŒ ìë™ ë²ˆì—­")
                    col_t1, col_t2 = st.columns(2)

                    with col_t1:
                        if st.button("ğŸ‡ºğŸ‡¸ ì˜ì–´ë¡œ ë²ˆì—­", key=f"trans_en_{key}", use_container_width=True):
                            with st.spinner("ì˜ì–´ë¡œ ë²ˆì—­ ì¤‘..."):
                                st.session_state[f"trans_en_{key}"] = translate_email(
                                    st.session_state[f"email_content_{key}"], "ì˜ì–´"
                                )
                                st.rerun()

                    with col_t2:
                        if st.button("ğŸ‡¨ğŸ‡³ ì¤‘êµ­ì–´ë¡œ ë²ˆì—­", key=f"trans_cn_{key}", use_container_width=True):
                            with st.spinner("ì¤‘êµ­ì–´ë¡œ ë²ˆì—­ ì¤‘..."):
                                st.session_state[f"trans_cn_{key}"] = translate_email(
                                    st.session_state[f"email_content_{key}"], "ì¤‘êµ­ì–´"
                                )
                                st.rerun()

                    if f"trans_en_{key}" in st.session_state:
                        st.text_area("ğŸ‡ºğŸ‡¸ ì˜ì–´ ë²ˆì—­", st.session_state[f"trans_en_{key}"], height=280, key=f"email_en_{key}")

                    if f"trans_cn_{key}" in st.session_state:
                        st.text_area("ğŸ‡¨ğŸ‡³ ì¤‘êµ­ì–´ ë²ˆì—­", st.session_state[f"trans_cn_{key}"], height=280, key=f"email_cn_{key}")
